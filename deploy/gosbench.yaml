---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gosbench-server
  namespace: gosbench
  labels:
    app: gosbench-server
    stack: gosbench
    type: server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gosbench-server
  template:
    metadata:
      labels:
        app: gosbench-server
        stack: gosbench
        type: server
    spec:
      hostNetwork: true
      containers:
        - name: gobench-server
          image: reg.deeproute.ai/deeproute-public/tools/gosbench-server:latest # need update
          imagePullPolicy: Always
          # image: ubuntu
          # imagePullPolicy: IfNotPresent
          # command: ["/bin/bash", "-c", "--"]
          # args: [ "while true; do sleep 30; done;" ]
          env:
          - name: CONFIGFILE
            value: "/config/config.yaml"
          - name: SERVERPORT
            value: "2000"
          - name: DEBUG
            value: "true"
          - name: TRACE
            value: "true"
          ports:
            - containerPort: 2000
          #   - containerPort: 2001
          securityContext:
            privileged: true
          volumeMounts:
          - name: config
            mountPath: /config/
      volumes:
      - name: config
        configMap:
          name: gosbench-config
---
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: gosbench-worker
  namespace: gosbench
  labels:
    k8s-app: gosbench-worker
spec: 
  selector:
    matchLabels:
      name: gosbench-worker
  template:
    metadata:
      labels:
        name: gosbench-worker
    spec:
      # tolerations:
      # - effect: NoSchedule
      #   key: node-role.kubernetes.io/master
      #hostNetwork: true
      containers:
        - name: gosbench-worker
          image: reg.deeproute.ai/deeproute-public/tools/gosbench-worker:latest # need update
          imagePullPolicy: "Always"
          env:
          - name: GATEWAY_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: GOSBENCH_IN_CONTAINER
            value: "true"
          - name: PROMETHEUSPORT
            value: "8888"
          - name: SERVERADDRESS
            value: "gosbench-server:2000"
          - name: DEBUG
            value: "false"
          - name: TRACE
            value: "true"
          # resources:
          #   limits:
          #     memory: 200Mi
          #     cpu: 200m
          #   requests:
          #     cpu: 10m
          #     memory: 10Mi
          ports:
            - containerPort: 8888
              hostPort:  7777  # expose as host port
          securityContext:
            privileged: true

---
apiVersion: v1
kind: Service
metadata:
  name: gosbench-server
  namespace: gosbench
  labels:
    app: gosbench-server
    stack: gosbench
spec:
  type: NodePort
  ports:
    - name: gosbench-server
      port: 2000
      targetPort: 2000
  selector:
    app: gosbench-server

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gosbench-config
  namespace: gosbench
data:
  config.yaml: |
    s3_configs:
      - access_key: testy
        secret_key: testy
        region: us-east-1
        endpoint: http://10.3.11.81:80
        skipSSLverify: true
        name: k1                 # better to match hostname
      - access_key: testy
        secret_key: testy
        region: us-east-1
        endpoint: http://10.3.11.82:80
        skipSSLverify: true
        name: k2
      - access_key: testy
        secret_key: testy
        region: us-east-1
        endpoint: http://10.3.11.83:80
        skipSSLverify: true
        name: k3
    
    # For generating annotations when we start/stop testcases
    # https://grafana.com/docs/http_api/annotations/#create-annotation
    grafana_config:
      endpoint: http://grafana
      username: admin
      password: grafana
    
    tests:
      - name: write-4k
        # read_weight: 20
        # write_weight: 80
        # delete_weight: 0
        # list_weight: 0
        write_weight: 100
        objects:
          size_min: 4
          size_max: 4
          # distribution: constant, random, sequential
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          # distribution: constant, random, sequential
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          # distribution: constant, random, sequential
          number_distribution: sequential
        # Name prefix for buckets and objects
        bucket_prefix: gosbench-prefix-4k-
        object_prefix: obj-
        # End after a set amount of time
        # Runtime in time.Duration - do not forget the unit please
        # stop_with_runtime: 60s # Example with 60 seconds runtime, may traverse the workqueue multiple times
        # End after a set amount of operations (per worker)
        #stop_with_ops: 10000
        oneshot: true
        # Number of s3 performance test servers to run in parallel
        workers: 3
        # Set wheter workers share the same buckets or not
        # If set to True - bucket names will have the worker # appended
        workers_share_buckets: True
        # Number of requests processed in parallel by each worker
        parallel_clients: 64
        # Remove all generated buckets and its content after run
        # clean_after: True
        clean_after: False
        write_option:
          # max_upload_parts: 10000
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: read-4k
        objects:
          size_min: 4
          size_max: 4
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          number_distribution: random
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-4k-
        object_prefix: obj-
        oneshot: true
        #stop_with_ops: 10000
        # stop_with_runtime: 60s # Example with 60 seconds runtime, may traverse the workqueue multiple times
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: False
        read_option:
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: clean-4k
        delete_weight: 100
        objects:
          size_min: 4
          size_max: 4
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-4k-
        object_prefix: obj-
        #stop_with_ops: 10000
        oneshot: true
        skip_prepare: true
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: True
      - name: write-64k
        # read_weight: 20
        # write_weight: 80
        # delete_weight: 0
        # list_weight: 0
        write_weight: 100
        objects:
          size_min: 64
          size_max: 64
          # distribution: constant, random, sequential
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          # distribution: constant, random, sequential
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          # distribution: constant, random, sequential
          number_distribution: sequential
        # Name prefix for buckets and objects
        bucket_prefix: gosbench-prefix-64k-
        object_prefix: obj-64k-
        # End after a set amount of time
        # Runtime in time.Duration - do not forget the unit please
        # stop_with_runtime: 60s # Example with 60 seconds runtime, may traverse the workqueue multiple times
        # End after a set amount of operations (per worker)
        #stop_with_ops: 10000
        oneshot: true
        # Number of s3 performance test servers to run in parallel
        workers: 3
        # Set wheter workers share the same buckets or not
        # If set to True - bucket names will have the worker # appended
        workers_share_buckets: True
        # Number of requests processed in parallel by each worker
        parallel_clients: 64
        # Remove all generated buckets and its content after run
        # clean_after: True
        clean_after: False
        write_option:
          # max_upload_parts: 10000
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: read-64k
        objects:
          size_min: 64
          size_max: 64
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          number_distribution: random
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-64k-
        object_prefix: obj-64k-
        #stop_with_ops: 10000
        oneshot: true
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: False
        read_option:
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: clean-64k
        delete_weight: 100
        objects:
          size_min: 64
          size_max: 64
          size_distribution: constant
          unit: KB
          number_min: 1
          number_max: 1000
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-64k-
        object_prefix: obj-64k-
        #stop_with_ops: 10000
        oneshot: true
        skip_prepare: true
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: True
      - name: write-4m
        # read_weight: 20
        # write_weight: 80
        # delete_weight: 0
        # list_weight: 0
        write_weight: 100
        objects:
          size_min: 4
          size_max: 4
          # distribution: constant, random, sequential
          size_distribution: constant
          unit: MB
          number_min: 1
          number_max: 1000
          # distribution: constant, random, sequential
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          # distribution: constant, random, sequential
          number_distribution: sequential
        # Name prefix for buckets and objects
        bucket_prefix: gosbench-prefix-4m-
        object_prefix: obj-4m-
        # End after a set amount of time
        # Runtime in time.Duration - do not forget the unit please
        # stop_with_runtime: 60s # Example with 60 seconds runtime, may traverse the workqueue multiple times
        # End after a set amount of operations (per worker)
        #stop_with_ops: 10000
        oneshot: true
        # Number of s3 performance test servers to run in parallel
        workers: 3
        # Set wheter workers share the same buckets or not
        # If set to True - bucket names will have the worker # appended
        workers_share_buckets: True
        # Number of requests processed in parallel by each worker
        parallel_clients: 64
        payload_generator: random # random or empty
        # Remove all generated buckets and its content after run
        # clean_after: True
        clean_after: False
        write_option:
          # max_upload_parts: 10000
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: read-4m
        objects:
          size_min: 4
          size_max: 4
          size_distribution: constant
          unit: MB
          number_min: 1
          number_max: 1000
          number_distribution: random
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-4m-
        object_prefix: obj-4m-
        #stop_with_ops: 10000
        oneshot: true
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: False
        read_option:
          # concurrency: 4
          # chunk_size: 40
          # unit: MB
      - name: clean-4m
        delete_weight: 100
        objects:
          size_min: 4
          size_max: 4
          size_distribution: constant
          unit: MB
          number_min: 1
          number_max: 1000
          number_distribution: sequential
        buckets:
          number_min: 1
          number_max: 10
          number_distribution: sequential
        bucket_prefix: gosbench-prefix-4m-
        object_prefix: obj-4m-
        #stop_with_ops: 10000
        oneshot: true
        skip_prepare: true
        workers: 3
        workers_share_buckets: True
        parallel_clients: 64
        clean_after: True
---
